# -*- coding: utf-8 -*-
"""tpsr2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10QkO-sAnSgzVAWI5Epzhmajolr2KP-J1
"""

!pip install pandas scikit-learn nltk imbalanced-learn folium plotly transformers torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import folium
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import RandomOverSampler
import nltk
from nltk.corpus import stopwords
import string
import torch
from transformers import BertTokenizer, BertForSequenceClassification
# Carregar o dataset
file_path = '/content/tripadvisor_hotel_reviews.csv'  # Caminho do arquivo no Colab
df = pd.read_csv(file_path)

# Visualizar as primeiras linhas do dataset
print(df.head())
# Baixar stopwords do NLTK
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    # Remover pontuação
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Converter para minúsculas
    text = text.lower()
    # Remover stopwords
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

# Aplicar pré-processamento às avaliações
df['Review'] = df['Review'].apply(preprocess_text)
# Dividir os dados em treino e teste
X = df['Review']
y = df['Rating']

# Converter o texto em vetores numéricos usando TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_tfidf = vectorizer.fit_transform(X)

# Dividir os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Treinar o modelo Naive Bayes
model = MultinomialNB()
model.fit(X_train, y_train)

# Avaliar o modelo
y_pred = model.predict(X_test)
print(f'Acurácia do modelo: {accuracy_score(y_test, y_pred):.2f}')
print(classification_report(y_test, y_pred))
# Criar uma matriz de características dos hotéis (exemplo simplificado)
df['Price'] = np.random.randint(50, 500, size=len(df))  # Preço aleatório
df['Location_Score'] = np.random.randint(1, 10, size=len(df))  # Pontuação de localização
df['Amenities_Score'] = np.random.randint(1, 10, size=len(df))  # Pontuação de comodidades

# Treinar um modelo KNN para recomendações
hotel_features = df[['Rating', 'Price', 'Location_Score', 'Amenities_Score']]
model_knn = NearestNeighbors(n_neighbors=5, metric='cosine')
model_knn.fit(hotel_features)
# Recomendar hotéis semelhantes a um hotel específico
hotel_index = 0  # Índice do hotel de referência
distances, indices = model_knn.kneighbors([hotel_features.iloc[hotel_index]])
print("Hotéis recomendados:", df.iloc[indices[0]])
# Aplicar oversampling para balancear o dataset
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X_tfidf, y)

# Dividir os dados balanceados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Treinar o modelo com dados balanceados
model = MultinomialNB()
model.fit(X_train, y_train)

# Avaliar o modelo
y_pred = model.predict(X_test)
print(f'Acurácia do modelo (após balanceamento): {accuracy_score(y_test, y_pred):.2f}')
print(classification_report(y_test, y_pred))
# Carregar o tokenizer e o modelo BERT
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model_bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)

# Tokenizar o texto
inputs = tokenizer(df['Review'].tolist(), padding=True, truncation=True, return_tensors='pt')
labels = torch.tensor(df['Rating'].tolist())

# Criar um DataLoader
from torch.utils.data import DataLoader, TensorDataset
dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)